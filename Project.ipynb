{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting whether a fellow will ultimately get placed at a company or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries and dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import category_encoders as ce\n",
    "\n",
    "data=pd.read_excel(\"Data_Pathrise.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pathrise_status</th>\n",
       "      <th>primary_track</th>\n",
       "      <th>cohort_tag</th>\n",
       "      <th>program_duration_days</th>\n",
       "      <th>placed</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>highest_level_of_education</th>\n",
       "      <th>length_of_job_search</th>\n",
       "      <th>biggest_challenge_in_search</th>\n",
       "      <th>professional_experience</th>\n",
       "      <th>work_authorization_status</th>\n",
       "      <th>number_of_interviews</th>\n",
       "      <th>number_of_applications</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Active</td>\n",
       "      <td>SWE</td>\n",
       "      <td>OCT19A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>3-5 months</td>\n",
       "      <td>Hearing back on my applications</td>\n",
       "      <td>3-4 years</td>\n",
       "      <td>Canada Citizen</td>\n",
       "      <td>2.0</td>\n",
       "      <td>900</td>\n",
       "      <td>Male</td>\n",
       "      <td>Non-Hispanic White or Euro-American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Active</td>\n",
       "      <td>PSO</td>\n",
       "      <td>JAN20A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Some College, No Degree</td>\n",
       "      <td>3-5 months</td>\n",
       "      <td>Getting past final round interviews</td>\n",
       "      <td>1-2 years</td>\n",
       "      <td>Citizen</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Non-Hispanic White or Euro-American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Closed Lost</td>\n",
       "      <td>Design</td>\n",
       "      <td>AUG19B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Employed Part-Time</td>\n",
       "      <td>Master's Degree</td>\n",
       "      <td>Less than one month</td>\n",
       "      <td>Figuring out which jobs to apply for</td>\n",
       "      <td>Less than one year</td>\n",
       "      <td>Citizen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>East Asian or Asian American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Closed Lost</td>\n",
       "      <td>PSO</td>\n",
       "      <td>AUG19B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Contractor</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Less than one month</td>\n",
       "      <td>Getting past final round interviews</td>\n",
       "      <td>Less than one year</td>\n",
       "      <td>Citizen</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Male</td>\n",
       "      <td>Decline to Self Identify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Placed</td>\n",
       "      <td>SWE</td>\n",
       "      <td>AUG19A</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>1-2 months</td>\n",
       "      <td>Hearing back on my applications</td>\n",
       "      <td>1-2 years</td>\n",
       "      <td>F1 Visa/OPT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>Male</td>\n",
       "      <td>East Asian or Asian American</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id pathrise_status primary_track cohort_tag  program_duration_days  placed  \\\n",
       "0   1          Active           SWE     OCT19A                    NaN       0   \n",
       "1   2          Active           PSO     JAN20A                    NaN       0   \n",
       "2   3     Closed Lost        Design     AUG19B                    0.0       0   \n",
       "3   4     Closed Lost           PSO     AUG19B                    0.0       0   \n",
       "4   5          Placed           SWE     AUG19A                   89.0       1   \n",
       "\n",
       "   employment_status  highest_level_of_education length_of_job_search  \\\n",
       "0          Unemployed          Bachelor's Degree           3-5 months   \n",
       "1          Unemployed    Some College, No Degree           3-5 months   \n",
       "2  Employed Part-Time            Master's Degree  Less than one month   \n",
       "3          Contractor          Bachelor's Degree  Less than one month   \n",
       "4          Unemployed          Bachelor's Degree           1-2 months   \n",
       "\n",
       "            biggest_challenge_in_search professional_experience  \\\n",
       "0       Hearing back on my applications               3-4 years   \n",
       "1   Getting past final round interviews               1-2 years   \n",
       "2  Figuring out which jobs to apply for      Less than one year   \n",
       "3   Getting past final round interviews      Less than one year   \n",
       "4       Hearing back on my applications               1-2 years   \n",
       "\n",
       "  work_authorization_status  number_of_interviews  number_of_applications  \\\n",
       "0            Canada Citizen                   2.0                     900   \n",
       "1                   Citizen                   6.0                       0   \n",
       "2                   Citizen                   0.0                       0   \n",
       "3                   Citizen                   5.0                      25   \n",
       "4               F1 Visa/OPT                  10.0                     100   \n",
       "\n",
       "  gender                                 race  \n",
       "0   Male  Non-Hispanic White or Euro-American  \n",
       "1   Male  Non-Hispanic White or Euro-American  \n",
       "2   Male         East Asian or Asian American  \n",
       "3   Male             Decline to Self Identify  \n",
       "4   Male         East Asian or Asian American  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look at the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data comprises information about 4 categories of applicants\n",
    "# 1 - Applicants who got placed through the program\n",
    "# 2 - Applicants who failed to get placed through the program\n",
    "# 3 - Applicants who did not accept admission offer or did not continue after the free 14 day trial period\n",
    "# 4 - Applicants who are currently enrolled in the program\n",
    "\n",
    "# To build our predictive model we need to analyse the data comprising the first 2 categories as stated above so let's filter to \n",
    "# get the same\n",
    "\n",
    "data = data[(data['pathrise_status']=='MIA') | (data['pathrise_status']=='Placed') | (data['pathrise_status']=='Withdrawn') | (data['pathrise_status']=='Withdrawn (Failed)')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# There are 4 columns (id, pathrise_status, cohort_tag and program_duration_days) which do not provide any valuable\n",
    "# information so we can get rid of them \n",
    "\n",
    "cols = [2,6,7,8,9,10,11,12,13,14,15,5]\n",
    "data = data[data.columns[cols]]\n",
    "\n",
    "# Renaming column 'employment_status ' to 'employment_status'\n",
    "data=data.rename(columns={\"employment_status \": \"employment_status\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "primary_track                    0\n",
       "employment_status              150\n",
       "highest_level_of_education      30\n",
       "length_of_job_search            55\n",
       "biggest_challenge_in_search     16\n",
       "professional_experience        109\n",
       "work_authorization_status      186\n",
       "number_of_interviews           134\n",
       "number_of_applications           0\n",
       "gender                         288\n",
       "race                            12\n",
       "placed                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the number of missing values in each feature\n",
    "# There are 9 features having missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing values for gender feature\n",
    "# Let's check the frequency of available values in the gender column \n",
    "data['gender'].value_counts()\n",
    "\n",
    "# We can see that ~ 75% of the values are Male so it's good enough to impute the missing values in this column with Male\n",
    "# Also we can remove the rows which contain the values 'Non-Binary' and 'Decline to Self Identify' since there are just 2 and 6 instances of them respectively.\n",
    "# By eliminating them we can reduce the number of categories to 2 which will make the model simpler\n",
    "\n",
    "data.drop(data[(data['gender'] == 'Non-Binary')].index, inplace = True)\n",
    "data.drop(data[(data['gender'] == 'Decline to Self Identify')].index, inplace = True)\n",
    "data['gender'].fillna(data['gender'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treating missing values for highest_level_of_education,biggest_challenge_in_search,length_of_job_search and race  \n",
    "# Columns highest_level_of_education,length_of_job_search, biggest_challenge_in_search and race have a low proportion of missing values\n",
    "# so we can simply drop the appropriate rows \n",
    "\n",
    "data = data[data['highest_level_of_education'].notna()]\n",
    "data = data[data['biggest_challenge_in_search'].notna()]\n",
    "data = data[data['length_of_job_search'].notna()]\n",
    "data = data[data['race'].notna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing values for employment_status using mode   \n",
    "# Combining the labels to fall under either 'Employed' or 'Unemployed'\n",
    "data=data.replace(\"Student\", \"Unemployed\")\n",
    "data=data.replace(\"Employed Full-Time\", \"Employed\")\n",
    "data=data.replace(\"Employed Part-Time\", \"Employed\")\n",
    "data=data.replace(\"Contractor\", \"Employed\")\n",
    "\n",
    "data['employment_status'].fillna(data['employment_status'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing values for work_authorization_status using mode\n",
    "# Combining similar visas together\n",
    "data=data.replace(\"F1 Visa/OPT\", \"F1\")\n",
    "data=data.replace(\"F1 Visa/CPT\", \"F1\")\n",
    "data=data.replace(\"STEM OPT\", \"F1\")\n",
    "data=data.replace(\"Other\", \"H1B\")\n",
    "\n",
    "data['work_authorization_status'].fillna(data['work_authorization_status'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing values for professional_experience using mode\n",
    "data['professional_experience'].fillna(data['professional_experience'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing values for number_of_interviews using median\n",
    "data['number_of_interviews'].fillna(data['number_of_interviews'].median(),inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical data encoding\n",
    "# Since most of the ML models accept only numeric features we need to convert the categorical variables to numbers such that the model is able to understand and extract valuable information.\n",
    "# We will use the ordinal encoder for the ordinal columns highest_level_of_education,professional_experience and length_of_job_search\n",
    "\n",
    "encoder= ce.OrdinalEncoder(cols=['highest_level_of_education','professional_experience','length_of_job_search'],return_df=True,\n",
    "                           mapping=[{'col':'highest_level_of_education',\n",
    "'mapping':{'Some High School':0,'High School Graduate':1,'GED or equivalent':2,'Some College, No Degree':3,'Bachelor\\'s Degree':4,'Master\\'s Degree':5,'Doctorate or Professional Degree':6}},\n",
    "                                    {'col':'professional_experience','mapping':{'Less than one year':0,'1-2 years':1,'3-4 years':2,'5+ years':3}},\n",
    "                                  {'col':'length_of_job_search','mapping':{'Less than one month':0,'1-2 months':1,'3-5 months':2,'6 months to a year':3,'Over a year':4}}] )\n",
    "data_transformed = encoder.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be using binary encoding for employment_status and gender \n",
    "data_transformed[\"employment_status\"] = np.where(data_transformed[\"employment_status\"].str.contains(\"Employed\"), 1, 0)\n",
    "data_transformed[\"gender\"] = np.where(data_transformed[\"gender\"].str.contains(\"Male\"), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For the remaining features we will use dummy encoding\n",
    "data_transformed = pd.get_dummies(data_transformed,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 1.687555\n",
      "Feature 1: 0.182737\n",
      "Feature 2: 0.009367\n",
      "Feature 3: 0.099443\n",
      "Feature 4: 0.776853\n",
      "Feature 5: 210.006115\n",
      "Feature 6: 0.205945\n",
      "Feature 7: 0.255779\n",
      "Feature 8: 1.707042\n",
      "Feature 9: 3.656150\n",
      "Feature 10: 1.333540\n",
      "Feature 11: 3.414085\n",
      "Feature 12: 0.097008\n",
      "Feature 13: 0.468873\n",
      "Feature 14: 0.098929\n",
      "Feature 15: 0.281249\n",
      "Feature 16: 0.099821\n",
      "Feature 17: 0.001242\n",
      "Feature 18: 0.342288\n",
      "Feature 19: 0.001297\n",
      "Feature 20: 2.357524\n",
      "Feature 21: 2.345113\n",
      "Feature 22: 1.716787\n",
      "Feature 23: 0.881383\n",
      "Feature 24: 0.428022\n",
      "Feature 25: 1.707042\n",
      "Feature 26: 0.318473\n",
      "Feature 27: 0.333584\n",
      "Feature 28: 0.402899\n",
      "Feature 29: 1.089389\n",
      "Feature 30: 1.171617\n",
      "Feature 31: 0.009522\n",
      "Feature 32: 0.713799\n",
      "Feature 33: 0.360023\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection\n",
    "# Chi-Squared Statistic\n",
    "# From the below test it's very difficult to say which are the most important features other than number_of_applications\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "X=data_transformed.drop('placed', 1)\n",
    "Y=data_transformed['placed']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=101)\n",
    "fs = SelectKBest(score_func=chi2, k='all')\n",
    "fs.fit(X_train, y_train)\n",
    "X_train_fs = fs.transform(X_train)\n",
    "X_test_fs = fs.transform(X_test)\n",
    "for i in range(len(fs.scores_)):\n",
    "    print('Feature %d: %f' % (i, fs.scores_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.62\n"
     ]
    }
   ],
   "source": [
    "# Creating a logistic regression model using all features\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "# fit the model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.62\n"
     ]
    }
   ],
   "source": [
    "# Creating a SVM model using all features\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# fit the model\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = clf.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.95\n"
     ]
    }
   ],
   "source": [
    "# Creating a RandomForest model using all features\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "# fit the model\n",
    "X_train_scaled = preprocessing.scale(X_train)\n",
    "X_test_scaled = preprocessing.scale(X_test)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "# evaluate the model\n",
    "yhat = clf.predict(X_test_scaled)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.71\n"
     ]
    }
   ],
   "source": [
    "# Creating a GradientBoosting model using all features\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# fit the model\n",
    "clf = GradientBoostingClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = clf.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.07\n"
     ]
    }
   ],
   "source": [
    "# Comparing results of different models\n",
    "# As we can see Logistic regression and SVM gave the best accuracy of 65.62%\n",
    "# Let's try to tune the SVM model\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# fit the model\n",
    "clf = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
    "clf.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = clf.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "\n",
    "# Changing the kernel to linear slightly improves the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model\n",
    "# Linear SVM classifier turns out to be the best model with an accuracy of 67.07%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
